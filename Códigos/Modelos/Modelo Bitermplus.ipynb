{"cells":[{"cell_type":"markdown","metadata":{"id":"k_jJy2MCdD9T"},"source":["#Instalação "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bh4Myg_zc35A"},"outputs":[],"source":["# reading daaset from Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkHpFaw2dLSU"},"outputs":[],"source":["!pip install emoji\n","!pip install simplejson\n","!pip install wmd\n","!pip install kneed\n","\n","#BTM\n","!pip install bitermplus\n","!pip install git+https://github.com/maximtrp/bitermplus.git\n","!pip install tmplot\n","!pip install git+https://github.com/maximtrp/tmplot.git\n","\n","#Metrics\n","!pip install octis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcjuQq_UdR9P"},"outputs":[],"source":[" # Packages to store and manipulate data\n","import pandas as pd\n","import numpy as np\n","# Example function using numpy:\n","from numpy import dot\n","from numpy.linalg import norm\n","import math\n","import os\n","import json\n","import simplejson as json\n","import csv\n","import string\n","import glob\n","import random\n","import time\n","import math\n","from datetime import datetime\n","pd.set_option('max_colwidth', 200)\n"," \n","# Plotting packages\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","import seaborn as sns\n","import pickle\n","import math\n","import wmd\n","from scipy import spatial\n","from scipy.spatial import distance\n","from scipy.spatial.distance import pdist, squareform\n","from collections import Counter\n","%matplotlib inline\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","import tmplot as tmp\n","from tmplot._helpers import get_phi\n","from tmplot._helpers import calc_terms_probs_ratio\n","\n","# Packages\n","import emoji\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import operator\n","from operator import itemgetter\n","from tqdm import tqdm\n","from collections import defaultdict\n","from textblob import TextBlob\n","import sys\n","import itertools\n","import spacy\n","from scipy.sparse import csr_matrix, issparse  # , todense\n","import sys\n","from collections import defaultdict\n","import multiprocessing\n","from pprint import pprint\n"," \n","# Gensim\n","import gensim\n","import gensim.downloader\n","from gensim.test.utils import common_texts\n","from gensim.models import Word2Vec\n","from gensim import models\n","from gensim import corpora\n","from gensim.models import CoherenceModel\n","import gensim.downloader as api\n","from gensim.test.utils import datapath, get_tmpfile\n","from gensim.models import KeyedVectors\n","from gensim.models.ldamulticore import LdaMulticore\n"," \n","# Model building package: Sklearn\n","import sklearn\n","from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.datasets import make_multilabel_classification\n","from sklearn.metrics.pairwise import euclidean_distances\n","from sklearn.metrics.pairwise import cosine_distances\n","from sklearn.metrics import pairwise_distances\n","from sklearn.metrics.pairwise import pairwise_kernels\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.manifold import TSNE\n","from sklearn.datasets import load_digits\n","# Cluster documents: Sklearn\n","from kneed import KneeLocator\n","from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import PCA\n"," \n","#BTM\n","import bitermplus as btm\n","from typing import List, Union, Tuple, Dict, Sequence, Any\n","from scipy.sparse import csr\n","from pandas import DataFrame, Series, concat\n","from sklearn.feature_extraction.text import CountVectorizer\n","import numpy as np\n","from bitermplus._btm import BTM\n"," \n","#PTM\n","import tomotopy as tp\n","\n","#Metrics\n","from octis.evaluation_metrics.metrics import AbstractMetric\n","from octis.dataset.dataset import Dataset\n","from gensim.corpora.dictionary import Dictionary\n","from gensim.models import CoherenceModel\n","import octis.configuration.citations as citations\n","import numpy as np\n","import itertools\n","from scipy import spatial\n","from sklearn.metrics import pairwise_distances\n","from operator import add\n","from octis.evaluation_metrics.rbo import rbo\n","import gensim.downloader as api\n","from gensim.models import KeyedVectors\n","from octis.evaluation_metrics.diversity_metrics import WordEmbeddingsInvertedRBO, \\\n","    WordEmbeddingsInvertedRBOCentroid, InvertedRBO\n","from itertools import combinations\n","from scipy.spatial.distance import cosine"]},{"cell_type":"markdown","metadata":{"id":"QXzUzxh8WH05"},"source":["#Importar Dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51wBO3uMdWQU"},"outputs":[],"source":["df = pd.read_json('/content/drive/dados_fevereiro_dia_de_semana_1.json')\n","\n","#Tokenizar\n","new_tweet = []\n","for tweet in df.clean_tweet:\n","    tweet_len = [word for word in tweet.split(' ') if len(word) >= 3]\n","    tweet_string = ' '.join(tweet_len)\n","    new_tweet.append(tweet_string)\n","df['clean_tweet'] = new_tweet\n","\n","stop = stopwords.words('english')\n","df['clean_tweet_tokenize'] = df['clean_tweet'].apply(lambda x: [item for item in str(x).split(' ')])\n","df.dropna()"]},{"cell_type":"markdown","metadata":{"id":"jrx3JvjPdqBq"},"source":["#Modelagem de Tópicos"]},{"cell_type":"code","source":["def get_words_freqs(\n","        docs: Union[List[str], np.ndarray, Series],\n","        **kwargs: dict) -> Tuple[csr.csr_matrix, np.ndarray, Dict]:\n","    \"\"\"Compute words vs documents frequency matrix.\n","    Parameters\n","    ----------\n","    docs : Union[List[str], np.ndarray, Series]\n","        Documents in any format that can be passed to\n","        :meth:`sklearn.feature_extraction.text.CountVectorizer` method.\n","    kwargs : dict\n","        Keyword arguments for\n","        :meth:`sklearn.feature_extraction.text.CountVectorizer` method.\n","    Returns\n","    -------\n","    Tuple[csr.csr_matrix, np.ndarray, Dict]\n","        Documents vs words matrix in CSR format,\n","        vocabulary as a numpy.ndarray of terms,\n","        and vocabulary as a dictionary of {term: id} pairs.\n","    Example\n","    -------\n","    >>> import pandas as pd\n","    >>> import bitermplus as btm\n","    >>> # Loading data\n","    >>> df = pd.read_csv(\n","    ...     'dataset/SearchSnippets.txt.gz', header=None, names=['texts'])\n","    >>> texts = df['texts'].str.strip().tolist()\n","    >>> # Vectorizing documents, obtaining full vocabulary and biterms\n","    >>> X, vocabulary, vocab_dict = btm.get_words_freqs(texts)\n","    \"\"\"\n","    vec = CountVectorizer(**kwargs)\n","    X = vec.fit_transform(docs)\n","    words = np.array(vec.get_feature_names())\n","    return X, words, vec.vocabulary_\n"],"metadata":{"id":"nlraJfmWfn1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importing data\n","texts = df['clean_tweet'].str.strip().tolist()\n","\n","# PREPROCESSING\n","# Obtaining terms frequency in a sparse matrix and corpus vocabulary\n","X, vocabulary, vocab_dict = get_words_freqs(texts)\n","tf = np.array(X.sum(axis=0)).ravel()\n","\n","# Vectorizing documents\n","docs_vec = btm.get_vectorized_docs(texts, vocabulary)\n","docs_lens = list(map(len, docs_vec))\n","\n","# Generating biterms\n","biterms = btm.get_biterms(docs_vec)\n","\n","# INITIALIZING AND RUNNING MODEL\n","model = btm.BTM(X, vocabulary, T=10)\n","model.fit(biterms, iterations=100)\n","p_zd = model.transform(docs_vec)"],"metadata":{"id":"3SZt85PcsJbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle as pkl\n","# Saving\n","with open(\"model.pkl\", \"wb\") as file:\n","    pkl.dump(model, file)\n","\n","# Loading\n","with open(\"model.pkl\", \"rb\") as file:\n","    model_train = pkl.load(file)"],"metadata":{"id":"R-r4xotdZG98"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Tópicos"],"metadata":{"id":"OtW9axhHxCoY"}},{"cell_type":"code","source":["top_words = btm.get_top_topic_words(\n","    model,\n","    words_num=10,)\n","top_words"],"metadata":{"id":"nZx3zzkM8Vh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics = []\n","for i in range(10):\n","  topics.append(top_words['topic'+str(i)].tolist())"],"metadata":{"id":"8CBQ1h1dJZau"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualização"],"metadata":{"id":"FR4UGgzxC3r_"}},{"cell_type":"code","source":["#Run the interactive report interface\n","tmp.report(model=model, docs=texts)"],"metadata":{"id":"Ozbwzr5_sWup"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_docs = btm.get_top_topic_docs(\n","    texts,\n","    p_zd,\n","    docs_num=10,\n","    )\n","top_docs"],"metadata":{"id":"AHHIj4H53WAZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Métricas"],"metadata":{"id":"oWOBEO3gVTlH"}},{"cell_type":"code","source":["# cast tweets to numpy array\n","docs = df.clean_tweet_tokenize.to_numpy()\n","\n","# create dictionary of all words in all documents\n","dictionary =  corpora.Dictionary(docs)\n","\n","# create variable containing length of dictionary/vocab\n","vocab_length = len(dictionary)\n","\n","# create BOW dictionary\n","bow_corpus = [dictionary.doc2bow(doc) for doc in docs]"],"metadata":{"id":"9EUcIY_wmlO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm_btm = CoherenceModel(topics=topics, \n","                          dictionary=dictionary, \n","                          corpus=bow_corpus, \n","                          texts=docs, \n","                          coherence='c_v')\n","\n","print(cm_btm.get_coherence())"],"metadata":{"id":"ZfBkrBZ4Vre2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["npmi = CoherenceModel(topics=topics, \n","                          dictionary=dictionary, \n","                          corpus=bow_corpus, \n","                          texts=docs,\n","                          coherence='c_npmi')\n","\n","print(npmi.get_coherence())"],"metadata":{"id":"AAHXfVWLVYiI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_word2index(list1, list2):\n","    words = set(list1)\n","    words = words.union(set(list2))\n","    word2index = {w: i for i, w in enumerate(words)}\n","    return word2index"],"metadata":{"id":"am3OWQUJ1YrZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Diversity Metrics:\n","class TopicDiversity(AbstractMetric):\n","    def __init__(self, topk=10):\n","        \"\"\"\n","        Initialize metric\n","        Parameters\n","        ----------\n","        topk: top k words on which the topic diversity will be computed\n","        \"\"\"\n","        AbstractMetric.__init__(self)\n","        self.topk = topk\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        Parameters\n","        ----------\n","        model_output : dictionary, output of the model\n","                       key 'topics' required.\n","        Returns\n","        -------\n","        td : score\n","        \"\"\"\n","        topics = model_output\n","        if topics is None:\n","            return 0\n","        if self.topk > len(topics[0]):\n","            raise Exception('Words in topics are less than ' + str(self.topk))\n","        else:\n","            unique_words = set()\n","            for topic in topics:\n","                unique_words = unique_words.union(set(topic[:self.topk]))\n","            td = len(unique_words) / (self.topk * len(topics))\n","            return td"],"metadata":{"id":"ljV2sN8eYxyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diversity = TopicDiversity()\n","diversity.score(topics)"],"metadata":{"id":"edPyABcRY0rr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class InvertedRBO(AbstractMetric):\n","    def __init__(self, topk=10, weight=0.9):\n","        \"\"\"\n","        Initialize metric Inverted Ranked-Biased Overlap\n","        :param topk: top k words on which the topic diversity will be computed\n","        :param weight: weight of each agreement at depth d. When set to 1.0, there is no weight, the rbo returns to\n","        average overlap. (default 0.9)\n","        \"\"\"\n","        super().__init__()\n","        self.topk = topk\n","        self.weight = weight\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        :param model_output : dictionary, output of the model. the 'topics' key is required.\n","        \"\"\"\n","        topics = model_output\n","        if topics is None:\n","            return 0\n","        if self.topk > len(topics[0]):\n","            raise Exception('Words in topics are less than topk')\n","        else:\n","            collect = []\n","            for list1, list2 in itertools.combinations(topics, 2):\n","                word2index = get_word2index(list1, list2)\n","                indexed_list1 = [word2index[word] for word in list1]\n","                indexed_list2 = [word2index[word] for word in list2]\n","                rbo_val = rbo(indexed_list1[:self.topk], indexed_list2[:self.topk], p=self.weight)[2]\n","                collect.append(rbo_val)\n","            return 1 - np.mean(collect)"],"metadata":{"id":"-MNdaROvxjGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b = InvertedRBO()\n","b.score(topics)"],"metadata":{"id":"nAqp1p3QZADQ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1EzA7oa7PV2Ubtm7PzEDICE7fxdmF_VkM","timestamp":1659454785210},{"file_id":"1xbaaQdY2JTGV3olQOn5yM46thEYc5h7I","timestamp":1644782015674},{"file_id":"1SYRVAF1z9ei5D25OM5s_W7a8Ra5vVFC-","timestamp":1644610045835}],"authorship_tag":"ABX9TyP54GpqZUjJNcFwn1a9IRTq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}