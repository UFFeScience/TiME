{"cells":[{"cell_type":"markdown","metadata":{"id":"k_jJy2MCdD9T"},"source":["#Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bh4Myg_zc35A"},"outputs":[],"source":["# reading daaset from Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkHpFaw2dLSU"},"outputs":[],"source":["!pip install emoji\n","!pip install simplejson\n","!pip install wmd\n","!pip install kneed\n","\n","#Metrics\n","!pip install octis\n","\n","!pip install tmplot\n","!pip install git+https://github.com/maximtrp/tmplot.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcjuQq_UdR9P"},"outputs":[],"source":[" # Packages to store and manipulate data\n","import pandas as pd\n","import numpy as np\n","# Example function using numpy:\n","from numpy import dot\n","from numpy.linalg import norm\n","import math\n","import os\n","import json\n","import simplejson as json\n","import csv\n","import string\n","import glob\n","import random\n","import time\n","import math\n","from datetime import datetime\n","pd.set_option('max_colwidth', 200)\n"," \n","# Plotting packages\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","import seaborn as sns\n","import pickle\n","import math\n","import wmd\n","from scipy import spatial\n","from scipy.spatial import distance\n","from scipy.spatial.distance import pdist, squareform\n","from collections import Counter\n","%matplotlib inline\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n"," \n","# Packages\n","import emoji\n","import re\n","import nltk\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import operator\n","from operator import itemgetter\n","from tqdm import tqdm\n","from collections import defaultdict\n","from textblob import TextBlob\n","import sys\n","import itertools\n","import spacy\n","from scipy.sparse import csr_matrix, issparse  # , todense\n","import sys\n","from collections import defaultdict\n","import multiprocessing\n","from pprint import pprint\n"," \n","# Gensim\n","import gensim\n","import gensim.downloader\n","from gensim.test.utils import common_texts\n","from gensim.models import Word2Vec\n","from gensim import models\n","from gensim import corpora\n","from gensim.models import CoherenceModel\n","import gensim.downloader as api\n","from gensim.test.utils import datapath, get_tmpfile\n","from gensim.models import KeyedVectors\n","from gensim.models.ldamulticore import LdaMulticore\n"," \n","# Model building package: Sklearn\n","import sklearn\n","from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.datasets import make_multilabel_classification\n","from sklearn.metrics.pairwise import euclidean_distances\n","from sklearn.metrics.pairwise import cosine_distances\n","from sklearn.metrics import pairwise_distances\n","from sklearn.metrics.pairwise import pairwise_kernels\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.manifold import TSNE\n","from sklearn.datasets import load_digits\n","# Cluster documents: Sklearn\n","from kneed import KneeLocator\n","from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import PCA\n","\n","#Metrics\n","from octis.evaluation_metrics.metrics import AbstractMetric\n","from octis.dataset.dataset import Dataset\n","from gensim.corpora.dictionary import Dictionary\n","from gensim.models import CoherenceModel\n","import octis.configuration.citations as citations\n","import numpy as np\n","import itertools\n","from scipy import spatial\n","from sklearn.metrics import pairwise_distances\n","from operator import add\n","from octis.evaluation_metrics.rbo import rbo\n","import gensim.downloader as api\n","from gensim.models import KeyedVectors\n","from octis.evaluation_metrics.diversity_metrics import WordEmbeddingsInvertedRBO, \\\n","    WordEmbeddingsInvertedRBOCentroid, InvertedRBO\n","from itertools import combinations\n","from scipy.spatial.distance import cosine"]},{"cell_type":"markdown","metadata":{"id":"QXzUzxh8WH05"},"source":["#Importar Dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51wBO3uMdWQU"},"outputs":[],"source":["df = pd.read_json('dados_fevereiro_semana_1.json')\n","#Tokenizar\n","\n","new_tweet = []\n","for tweet in df.clean_tweet:\n","    tweet_len = [word for word in tweet.split(' ') if len(word) >= 3]\n","    tweet_string = ' '.join(tweet_len)\n","    new_tweet.append(tweet_string)\n","df['clean_tweet'] = new_tweet\n","\n","stop = stopwords.words('english')\n","df['clean_tweet_tokenize'] = df['clean_tweet'].apply(lambda x: [item for item in str(x).split(' ')])\n","df.dropna()\n","df"]},{"cell_type":"markdown","metadata":{"id":"jrx3JvjPdqBq"},"source":["#Modelagem de Tópico"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7BYMlo1fUws"},"outputs":[],"source":["# GENSIM\n","class LdaModel:\n","    \n","    def __init__(self, column, num_topics):\n","        self.column = column\n","        self.num_topics = num_topics\n","        self.__preparing_application()\n","        self.__applying_topic_modelling_lda()\n","        self.__save_the_model()\n","        \n","    def __preparing_application(self):\n","        # Create Dictionary\n","        self.id2word = corpora.Dictionary(self.column.to_numpy())\n","        # Create Corpus: Term Document Frequency\n","        self.corpus = [self.id2word.doc2bow(text) for text in self.column]\n","        \n","    def __applying_topic_modelling_lda(self):\n","        # Build LDA model\n","        self.lda_model = gensim.models.ldamodel.LdaModel(corpus=self.corpus,\n","                                                   id2word=self.id2word,\n","                                                   num_topics=self.num_topics, \n","                                                   random_state=42) \n","        \n","    def get_lda(self, topic_number):\n","        # Shows the weight of each word in the topic\n","        return self.lda_model.print_topics(topic_number)\n","\n","    def get_topics_lda_set_tokes(self):\n","        self.dic_topic_set = {}\n","        for index, topic in self.lda_model.show_topics(formatted=False, num_words= 30): #More tokens\n","            name = 'Topic ' + str(index)\n","            self.dic_topic_set[name] = ([w[0] for w in topic])\n","        return self.dic_topic_set\n","\n","    def get_display_topics_lda_set_tokes(self):\n","        self.get_topics_lda_set_tokes()\n","        dataframe_topics = pd.DataFrame(data=self.dic_topic_set)\n","        return dataframe_topics\n","\n","    def get_topics_lda(self):\n","        # Filtering for words \n","        words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in self.lda_model.print_topics()]\n","        \n","        # Create Topics\n","        topics = [t[0:10] for t in (words)]\n","        self.dic_topic = {}\n","        self.list_topic = []\n","        # Getting the topics\n","        for id, t in enumerate(topics): \n","          topic = 'Topic ' + str(id)\n","          self.list_topic.append(t)\n","          self.dic_topic[topic] = t\n","        \n","        return self.dic_topic\n","\n","    def get_topic_in_list(self):\n","        self.get_topics_lda()\n","        return self.list_topic\n","      \n","    def get_display_topics_lda(self):\n","        self.get_topics_lda()\n","        dataframe_topics = pd.DataFrame(data=self.dic_topic)\n","        return dataframe_topics\n","\n","    def __save_the_model(self):\n","        self.lda_model.save('lda.model_train')\n","\n","    def plot(self):\n","        pyLDAvis.enable_notebook()\n","        lda_visualization = pyLDAvis.gensim_models.prepare(self.lda_model, self.corpus_select, self.id2word, sort_topics=False)\n","        return pyLDAvis.display(lda_visualization)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALiS6B5VlJsC"},"outputs":[],"source":["column = df['clean_tweet_tokenize'] \n","lda_model = LdaModel(column, 10)"]},{"cell_type":"markdown","metadata":{"id":"IAho2O15p4pB"},"source":["#Tópicos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvQ0ywtIOeq9"},"outputs":[],"source":["lda_topic= lda_model.get_display_topics_lda()\n","lda_topic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KzQjRnrwTgZ"},"outputs":[],"source":["topics = lda_model.get_topic_in_list()"]},{"cell_type":"markdown","metadata":{"id":"nWhqTooApt-q"},"source":["# Visualização"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7ilAKcoGZg1"},"outputs":[],"source":["!pip install pyLDAvis\n","import pyLDAvis\n","import pyLDAvis.gensim_models\n","lda_model.plot()"]},{"cell_type":"markdown","metadata":{"id":"oWOBEO3gVTlH"},"source":["# Métricas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EUcIY_wmlO8"},"outputs":[],"source":["# cast tweets to numpy array\n","docs = df.clean_tweet_tokenize.to_numpy()\n","# create dictionary of all words in all documents\n","dictionary =  corpora.Dictionary(docs)\n","# create BOW dictionary\n","bow_corpus = [dictionary.doc2bow(doc) for doc in docs]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfBkrBZ4Vre2"},"outputs":[],"source":["cm_lda = CoherenceModel(topics=topics, \n","                          dictionary=dictionary, \n","                          corpus=bow_corpus, \n","                          texts=docs, \n","                          coherence='c_v')\n","\n","print(cm_lda.get_coherence()) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAHXfVWLVYiI"},"outputs":[],"source":["npmi = CoherenceModel(topics=topics, \n","                          dictionary=dictionary, \n","                          corpus=bow_corpus, \n","                          texts=docs,\n","                          coherence='c_npmi')\n","\n","print(npmi.get_coherence())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"am3OWQUJ1YrZ"},"outputs":[],"source":["def get_word2index(list1, list2):\n","    words = set(list1)\n","    words = words.union(set(list2))\n","    word2index = {w: i for i, w in enumerate(words)}\n","    return word2index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljV2sN8eYxyt"},"outputs":[],"source":["#Diversity Metrics:\n","class TopicDiversity(AbstractMetric):\n","    def __init__(self, topk=10):\n","        \"\"\"\n","        Initialize metric\n","        Parameters\n","        ----------\n","        topk: top k words on which the topic diversity will be computed\n","        \"\"\"\n","        AbstractMetric.__init__(self)\n","        self.topk = topk\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        Parameters\n","        ----------\n","        model_output : dictionary, output of the model\n","                       key 'topics' required.\n","        Returns\n","        -------\n","        td : score\n","        \"\"\"\n","        topics = model_output\n","        if topics is None:\n","            return 0\n","        if self.topk > len(topics[0]):\n","            raise Exception('Words in topics are less than ' + str(self.topk))\n","        else:\n","            unique_words = set()\n","            for topic in topics:\n","                unique_words = unique_words.union(set(topic[:self.topk]))\n","            td = len(unique_words) / (self.topk * len(topics))\n","            return td"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edPyABcRY0rr"},"outputs":[],"source":["diversity = TopicDiversity()\n","diversity.score(topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MNdaROvxjGg"},"outputs":[],"source":["class InvertedRBO(AbstractMetric):\n","    def __init__(self, topk=10, weight=0.9):\n","        \"\"\"\n","        Initialize metric Inverted Ranked-Biased Overlap\n","        :param topk: top k words on which the topic diversity will be computed\n","        :param weight: weight of each agreement at depth d. When set to 1.0, there is no weight, the rbo returns to\n","        average overlap. (default 0.9)\n","        \"\"\"\n","        super().__init__()\n","        self.topk = topk\n","        self.weight = weight\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        :param model_output : dictionary, output of the model. the 'topics' key is required.\n","        \"\"\"\n","        topics = model_output\n","        if topics is None:\n","            return 0\n","        if self.topk > len(topics[0]):\n","            raise Exception('Words in topics are less than topk')\n","        else:\n","            collect = []\n","            for list1, list2 in itertools.combinations(topics, 2):\n","                word2index = get_word2index(list1, list2)\n","                indexed_list1 = [word2index[word] for word in list1]\n","                indexed_list2 = [word2index[word] for word in list2]\n","                rbo_val = rbo(indexed_list1[:self.topk], indexed_list2[:self.topk], p=self.weight)[2]\n","                collect.append(rbo_val)\n","            return 1 - np.mean(collect)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAqp1p3QZADQ"},"outputs":[],"source":["b = InvertedRBO()\n","b.score(topics)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1SYRVAF1z9ei5D25OM5s_W7a8Ra5vVFC-","timestamp":1658351688642}],"authorship_tag":"ABX9TyOVUg2Qj6+YMkx3jvQYTOJf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}