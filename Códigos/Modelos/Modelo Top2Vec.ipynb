{"cells":[{"cell_type":"markdown","metadata":{"id":"k_jJy2MCdD9T"},"source":["#Instalação "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bh4Myg_zc35A"},"outputs":[],"source":["# reading daaset from Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkHpFaw2dLSU"},"outputs":[],"source":["!pip install emoji\n","!pip install simplejson\n","!pip install wmd\n","!pip install kneed\n","\n","#Top2Vec\n","!pip install top2vec\n","!pip install top2vec[sentence_encoders]\n","!pip install top2vec[sentence_transformers]\n","!pip install top2vec[indexing]\n","\n","#Metrics\n","!pip install octis\n","\n","!pip install tmplot\n","!pip install git+https://github.com/maximtrp/tmplot.git\n","\n","!pip install -U contextualized_topic_models\n","\n","#embedding\n","!pip install spacy\n","!python -m spacy download en_core_web_sm\n","!pip install pyyaml==5.4.1\n","!pip install flair\n","\n","\n","!pip install numpy scipy\n","!pip install scikit-learn\n","!pip install numba\n","!pip install umap-learn\n","!pip install umap-learn\n","!pip install umap-learn[parametric_umap]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcjuQq_UdR9P"},"outputs":[],"source":["# Packages to store and manipulate data\n","import pandas as pd\n","import numpy as np\n","# Example function using numpy:\n","from numpy import dot\n","from numpy.linalg import norm\n","import math\n","import os\n","import json\n","import simplejson as json\n","import csv\n","import string\n","import glob\n","import random\n","import time\n","import math\n","from datetime import datetime\n","pd.set_option('max_colwidth', 200)\n"," \n","# Plotting packages\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","import seaborn as sns\n","import pickle\n","import math\n","import wmd\n","from scipy import spatial\n","from scipy.spatial import distance\n","from scipy.spatial.distance import pdist, squareform\n","from collections import Counter\n","%matplotlib inline\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","import tmplot as tmp\n","from tmplot._helpers import get_phi\n","from tmplot._helpers import calc_terms_probs_ratio\n"," \n","# Packages\n","import emoji\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import operator\n","from operator import itemgetter\n","from tqdm import tqdm\n","from collections import defaultdict\n","from textblob import TextBlob\n","import sys\n","import itertools\n","import spacy\n","from scipy.sparse import csr_matrix, issparse  # , todense\n","import sys\n","from collections import defaultdict\n","import multiprocessing\n","from pprint import pprint\n","from contextualized_topic_models.evaluation.measures import CoherenceNPMI\n","from hdbscan import HDBSCAN\n"," \n","# Gensim\n","import gensim\n","import gensim.downloader\n","from gensim.test.utils import common_texts\n","from gensim.models import Word2Vec\n","from gensim import models\n","from gensim import corpora\n","from gensim.models import CoherenceModel\n","import gensim.downloader as api\n","from gensim.test.utils import datapath, get_tmpfile\n","from gensim.models import KeyedVectors\n","from gensim.models.ldamulticore import LdaMulticore\n"," \n","# Model building package: Sklearn\n","import sklearn\n","from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.datasets import make_multilabel_classification\n","from sklearn.metrics.pairwise import euclidean_distances\n","from sklearn.metrics.pairwise import cosine_distances\n","from sklearn.metrics import pairwise_distances\n","from sklearn.metrics.pairwise import pairwise_kernels\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.manifold import TSNE\n","from sklearn.datasets import load_digits\n","# Cluster documents: Sklearn\n","from kneed import KneeLocator\n","from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import PCA\n"," \n","#Top2Vec\n","#Embeddings\n","from top2vec import Top2Vec\n","import umap\n","\n","#Metrics\n","from octis.evaluation_metrics.metrics import AbstractMetric\n","from octis.dataset.dataset import Dataset\n","from gensim.corpora.dictionary import Dictionary\n","from gensim.models import CoherenceModel\n","import octis.configuration.citations as citations\n","import numpy as np\n","import itertools\n","from scipy import spatial\n","from sklearn.metrics import pairwise_distances\n","from operator import add\n","from octis.evaluation_metrics.rbo import rbo\n","import gensim.downloader as api\n","from gensim.models import KeyedVectors\n","from octis.evaluation_metrics.diversity_metrics import WordEmbeddingsInvertedRBO, \\\n","    WordEmbeddingsInvertedRBOCentroid, InvertedRBO\n","from itertools import combinations\n","from scipy.spatial.distance import cosine"]},{"cell_type":"markdown","metadata":{"id":"QXzUzxh8WH05"},"source":["#Importar Dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQy0nfsjDCQk"},"outputs":[],"source":["df = pd.read_json('/content/drive/dados_fevereiro_semana_1.json')\n","\n","#Tokenizar\n","new_tweet = []\n","for tweet in df.clean_tweet:\n","    tweet_len = [word for word in tweet.split(' ') if len(word) >= 3]\n","    tweet_string = ' '.join(tweet_len)\n","    new_tweet.append(tweet_string)\n","df['clean_tweet'] = new_tweet\n","\n","stop = stopwords.words('english')\n","df['clean_tweet_tokenize'] = df['clean_tweet'].apply(lambda x: [item for item in str(x).split(' ')])\n","df.dropna()"]},{"cell_type":"markdown","metadata":{"id":"_T9eB6CWXZ_k"},"source":["#Modelagem de Tópico"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YE1ceH-vP8J6"},"outputs":[],"source":["# cast tweets to numpy array\n","docs = df.clean_tweet_tokenize.to_numpy()\n","\n","# create dictionary of all words in all documents\n","dictionary =  corpora.Dictionary(docs)\n","\n","# create BOW dictionary\n","bow_corpus = [dictionary.doc2bow(doc) for doc in docs]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QvV5Ld-0QDF_"},"outputs":[],"source":["np.random.seed(0)\n","doc = df.clean_tweet.to_list()\n","\n","#UMAP\n","umap_args_edit = {'n_neighbors': 15, 'n_components': 5, 'metric': 'cosine', 'random_state' : 42}\n","\n","model = Top2Vec(doc, embedding_model='distiluse-base-multilingual-cased', umap_args = umap_args_edit)"]},{"cell_type":"code","source":["model.save(\"model_train\")\n","topic_model_test = Top2Vec.load(\"model_train\")\n","#topic_model_test.add_documents()"],"metadata":{"id":"C_UqPnvxasbC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DliyLSEFSmby"},"source":["#Tópicos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUXNtoljSU0r"},"outputs":[],"source":["model.get_num_topics()\n","topic_words, word_scores, topic_nums = model.get_topics(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFSZFWSSSgrU"},"outputs":[],"source":["topic = pd.DataFrame()\n","topics = []\n","for i in range(0, len(topic_words)):\n","  name = 'Topic '+ str(i)\n","  top = []\n","  for j in range(10):\n","    top.append(topic_words[i][j])\n","  topics.append(top)\n","  topic[name] = top\n","\n","topic "]},{"cell_type":"markdown","metadata":{"id":"oWOBEO3gVTlH"},"source":["#Métricas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EUcIY_wmlO8"},"outputs":[],"source":["# cast tweets to numpy array\n","docs = df.clean_tweet_tokenize.to_numpy()\n","\n","# create dictionary of all words in all documents\n","dictionary =  corpora.Dictionary(docs)\n","\n","# filter extreme cases out of dictionary\n","#dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000, keep_tokens=None)\n","\n","# create variable containing length of dictionary/vocab\n","vocab_length = len(dictionary)\n","\n","# create BOW dictionary\n","bow_corpus = [dictionary.doc2bow(doc) for doc in docs]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfBkrBZ4Vre2"},"outputs":[],"source":["cm_bertopic = CoherenceModel(topics=topics, \n","                          dictionary=dictionary, \n","                          corpus=bow_corpus, \n","                          texts=docs, \n","                          coherence='c_v')\n","\n","print(cm_bertopic.get_coherence())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAHXfVWLVYiI"},"outputs":[],"source":["npmi = CoherenceModel(topics=topics, \n","                          dictionary=dictionary, \n","                          corpus=bow_corpus, \n","                          texts=docs,\n","                          coherence='c_npmi')\n","\n","print(npmi.get_coherence())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"am3OWQUJ1YrZ"},"outputs":[],"source":["def get_word2index(list1, list2):\n","    words = set(list1)\n","    words = words.union(set(list2))\n","    word2index = {w: i for i, w in enumerate(words)}\n","    return word2index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljV2sN8eYxyt"},"outputs":[],"source":["#Diversity Metrics:\n","class TopicDiversity(AbstractMetric):\n","    def __init__(self, topk=10):\n","        \"\"\"\n","        Initialize metric\n","        Parameters\n","        ----------\n","        topk: top k words on which the topic diversity will be computed\n","        \"\"\"\n","        AbstractMetric.__init__(self)\n","        self.topk = topk\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        Parameters\n","        ----------\n","        model_output : dictionary, output of the model\n","                       key 'topics' required.\n","        Returns\n","        -------\n","        td : score\n","        \"\"\"\n","        topics = model_output\n","        if topics is None:\n","            return 0\n","        if self.topk > len(topics[0]):\n","            raise Exception('Words in topics are less than ' + str(self.topk))\n","        else:\n","            unique_words = set()\n","            for topic in topics:\n","                unique_words = unique_words.union(set(topic[:self.topk]))\n","            td = len(unique_words) / (self.topk * len(topics))\n","            return td"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edPyABcRY0rr"},"outputs":[],"source":["diversity = TopicDiversity()\n","diversity.score(topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MNdaROvxjGg"},"outputs":[],"source":["class InvertedRBO(AbstractMetric):\n","    def __init__(self, topk=10, weight=0.9):\n","        \"\"\"\n","        Initialize metric Inverted Ranked-Biased Overlap\n","        :param topk: top k words on which the topic diversity will be computed\n","        :param weight: weight of each agreement at depth d. When set to 1.0, there is no weight, the rbo returns to\n","        average overlap. (default 0.9)\n","        \"\"\"\n","        super().__init__()\n","        self.topk = topk\n","        self.weight = weight\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        :param model_output : dictionary, output of the model. the 'topics' key is required.\n","        \"\"\"\n","        topics = model_output\n","        if topics is None:\n","            return 0\n","        if self.topk > len(topics[0]):\n","            raise Exception('Words in topics are less than topk')\n","        else:\n","            collect = []\n","            for list1, list2 in itertools.combinations(topics, 2):\n","                word2index = get_word2index(list1, list2)\n","                indexed_list1 = [word2index[word] for word in list1]\n","                indexed_list2 = [word2index[word] for word in list2]\n","                rbo_val = rbo(indexed_list1[:self.topk], indexed_list2[:self.topk], p=self.weight)[2]\n","                collect.append(rbo_val)\n","            return 1 - np.mean(collect)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAqp1p3QZADQ"},"outputs":[],"source":["b = InvertedRBO()\n","b.score(topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8Gz-3PT1sxc"},"outputs":[],"source":["#Similarity Metrics:\n","class PairwiseJaccardSimilarity(AbstractMetric):\n","    def __init__(self, topk=10):\n","        \"\"\"\n","        Initialize metric Pairwise Jaccard Similarity\n","        Parameters\n","        ----------\n","        :param topk: top k words on which the topic diversity will be computed\n","        \"\"\"\n","        super().__init__()\n","        self.topk = topk\n","\n","    def score(self, model_output):\n","        \"\"\"\n","        Retrieves the score of the metric\n","        :return PJS\n","        \"\"\"\n","        topics = model_output\n","        sim = 0\n","        count = 0\n","        for list1, list2 in combinations(topics, 2):\n","            intersection = len(list(set(list1[:self.topk]).intersection(list2[:self.topk])))\n","            union = (len(list1[:self.topk]) + len(list2[:self.topk])) - intersection\n","            count = count + 1\n","            sim = sim + (float(intersection) / union)\n","        return sim / count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLHufrTkd45Z"},"outputs":[],"source":["jaccard = PairwiseJaccardSimilarity()\n","jaccard.score(topics)"]}],"metadata":{"colab":{"collapsed_sections":["k_jJy2MCdD9T","QXzUzxh8WH05","DliyLSEFSmby","oWOBEO3gVTlH"],"provenance":[{"file_id":"1hexlj1VdMKK_fgh9baBph2zemw9K8qt-","timestamp":1657743991843},{"file_id":"1W_AZE6Pf4n2RtYhqnD6aTi2yM9ieM00d","timestamp":1647463058070},{"file_id":"1Nn1r2iIy6fGKO3y5Ivz9zfoCjJffViu0","timestamp":1643386890127},{"file_id":"1SYRVAF1z9ei5D25OM5s_W7a8Ra5vVFC-","timestamp":1643132887929}],"authorship_tag":"ABX9TyNhdcTn9Roh6fL8rKTd6x5s"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}